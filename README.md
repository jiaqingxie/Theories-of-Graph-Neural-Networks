# Awesome Collection of Graph Neural Network Theory Papers
Theoretical Foundations of Graph Neural Networks, Jiaqing Xie (ETH), Yuxin Wang (Fudan), Ziheng Chi (ETH)

This collection of Graph Neural Network (GNN) works distinguishes itself from other existing collections of GNN survey papers. It assists in crafting theoretical references related to GNNs and, more crucially, offers a more expansive viewpoint on the evolution of GNN theories, such as expressive power and SE(3) equivariant power, in the past few years.

In the second part, using domain graph neural networks to explain important natural science theories such as PDE, biochemistry are included. Ultimately we won't consider any social science relateds networks.  

### Some General Theoretical GNN Surveys

1. Zhou, Yu, et al. [Graph neural networks: Taxonomy, advances, and trends.](https://dl.acm.org/doi/full/10.1145/3495161?casa_token=wnutK67-_XQAAAAA:lMyEyQ2PckAAPoQX5V3hfF6lyxFoLjLhFjEH387d8ukre5fAn2w0pBLjREG4yqd2QEtD9Xd_VsMl76o) ACM Transactions on Intelligent Systems and Technology (TIST) 13.1 (2022): 1-54.

2. Liao, Renjie. [Deep Learning on Graphs: Theory, Models, Algorithms and Applications.](https://dam-oclc.bac-lac.gc.ca/download?is_thesis=1&oclc_number=1334506861&id=353a2bc9-9702-4aff-96e6-419d14993f74&fileName=Liao_Renjie_202106_PhD_thesis.pdf) University of Toronto (Canada), 2021.

3. Ritzert, Martin. [Learning on graphs with logic and neural networks.](https://publications.rwth-aachen.de/record/833937/files/833937.pdf) Diss. Dissertation, RWTH Aachen University, 2021, 2021.

4. Buffelli, Davide. [Improving the Effectiveness of Graph Neural Networks in Practical Scenarios.](https://www.research.unipd.it/bitstream/11577/3472978/2/thesis_pdfa.pdf) (2023).


55. Yuan, Hao, et al. [Explainability in graph neural networks: A taxonomic survey.](https://ieeexplore.ieee.org/iel7/34/4359286/09875989.pdf?casa_token=4PmyoZmRbbIAAAAA:_zoL60_ANI70lDasuiqaf8yT0kIWs4YLU5CQH6cl3Krj2ce3XyUir5qlG-1SUGTtegHSRP5nyOOG) IEEE Transactions on Pattern Analysis and Machine Intelligence (2022).

6. Khoshraftar, Shima, and Aijun An. [A survey on graph representation learning methods.](https://arxiv.org/pdf/2204.01855) arXiv preprint arXiv:2204.01855 (2022).


### Expressive Power of Graph Neural Networks (WL-test, Equivariance, Invariance)

1. Souza, Amauri, et al. [Provably expressive temporal graph networks.](https://proceedings.neurips.cc/paper_files/paper/2022/file/d029c97ee0db162c60f2ebc9cb93387e-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 32257-32269.

2. Balcilar, Muhammet, et al. [Analyzing the expressive power of graph neural networks in a spectral perspective.](https://hal-normandie-univ.archives-ouvertes.fr/hal-03135633/document) Proceedings of the International Conference on Learning Representations (ICLR). 2021.

3. Sato, Ryoma. [A survey on the expressive power of graph neural networks.](https://arxiv.org/pdf/2003.04078) arXiv preprint arXiv:2003.04078 (2020).

4. Rampášek, Ladislav, et al. [Recipe for a general, powerful, scalable graph transformer.](https://proceedings.neurips.cc/paper_files/paper/2022/file/5d4834a159f1547b267a05a4e2b7cf5e-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 14501-14515.

5. Bodnar, Cristian, et al. [Weisfeiler and lehman go cellular: Cw networks.](https://proceedings.neurips.cc/paper/2021/file/157792e4abb490f99dbd738483e0d2d4-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 2625-2640.


6. Bouritsas, Giorgos, et al. [Improving graph neural network expressivity via subgraph isomorphism counting.](https://ieeexplore.ieee.org/iel7/34/4359286/09721082.pdf?casa_token=VNIJNDkJyVsAAAAA:32T2nnL6OE9OKx9syJOjRN2-rxGOVfLIE1Rto_p64TfCqCYCC5EL8YOIoIFTPTo9GfwomA03yAUk) IEEE Transactions on Pattern Analysis and Machine Intelligence 45.1 (2022): 657-668.


7. Frasca, Fabrizio, et al. [Understanding and extending subgraph gnns by rethinking their symmetries.](https://proceedings.neurips.cc/paper_files/paper/2022/file/cb2a4cc70db72ea779abd01107782c7b-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 31376-31390.

8. Vignac, Clement, Andreas Loukas, and Pascal Frossard. [Building powerful and equivariant graph neural networks with structural message-passing.](https://proceedings.neurips.cc/paper/2020/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf) Advances in neural information processing systems 33 (2020): 14143-14155.

9. Ma, Jiaqi, Junwei Deng, and Qiaozhu Mei. [Subgroup generalization and fairness of graph neural networks.](https://proceedings.neurips.cc/paper/2021/file/08425b881bcde94a383cd258cea331be-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 1048-1061. 


10. Fatemi, Bahare, Layla El Asri, and Seyed Mehran Kazemi. [SLAPS: Self-supervision improves structure learning for graph neural networks.](https://proceedings.neurips.cc/paper/2021/file/bf499a12e998d178afd964adf64a60cb-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 22667-22681.


11. Wijesinghe, Asiri, and Qing Wang. [A new perspective on" how graph neural networks go beyond weisfeiler-lehman?".](https://openreview.net/pdf?id=uxgg9o7bI_3) International Conference on Learning Representations. 2022.


12. Papp, Pál András, and Roger Wattenhofer. [A theoretical comparison of graph neural network extensions.](https://proceedings.mlr.press/v162/papp22a/papp22a.pdf) International Conference on Machine Learning. PMLR, 2022.


13. Suresh, Susheel, et al. [Breaking the limit of graph neural networks by improving the assortativity of graphs with local mixing patterns.](https://arxiv.org/pdf/2106.06586) arXiv preprint arXiv:2106.06586 (2021).


14. Zhao, Lingxiao, Neil Shah, and Leman Akoglu. [A practical, progressively-expressive GNN.](https://proceedings.neurips.cc/paper_files/paper/2022/file/dc89a0709f213fd0ac4b1172719b2c38-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 34106-34120.


15. Zhang, Bohang, et al. [Rethinking the expressive power of gnns via graph biconnectivity.](https://arxiv.org/pdf/2301.09505) arXiv preprint arXiv:2301.09505 (2023).


16. Chen, Lei, Zhengdao Chen, and Joan Bruna. [On graph neural networks versus graph-augmented mlps.](https://arxiv.org/pdf/2010.15116) arXiv preprint arXiv:2010.15116 (2020).


17. Long, Qingqing, et al. [Theoretically improving graph neural networks via anonymous walk graph kernels.](https://dl.acm.org/doi/pdf/10.1145/3442381.3449951?casa_token=xBCQjgw4Z_EAAAAA:Vkei7a3URmkPTsYt5eoBhlTswvUS-17Gr6Dpqt40u6RX7_au8zzh_zWGdH32OYJG7dwh8aX4EoT3kFU) Proceedings of the Web Conference 2021. 2021.


18. Dash, Tirtharaj, Ashwin Srinivasan, and Lovekesh Vig. [Incorporating symbolic domain knowledge into graph neural networks.](https://link.springer.com/article/10.1007/s10994-021-05966-z) Machine Learning 110.7 (2021): 1609-1636.


19. Cahill, Jameson, et al. [Group-invariant max filtering.](https://arxiv.org/pdf/2205.14039) arXiv preprint arXiv:2205.14039 (2022).


20. Maehara, Takanori, and Hoang NT. [Learning on random balls is sufficient for estimating (some) graph parameters.](https://proceedings.neurips.cc/paper/2021/file/08f36fcf88c0a84c19a6ed437b9cbcc9-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 1126-1141.


21. Wang, Hanchen, et al. [Neural Subgraph Counting with Wasserstein Estimator.](https://dl.acm.org/doi/pdf/10.1145/3514221.3526163?casa_token=JcZZTe9C7N4AAAAA:RoOx0OjbDyUV0QAuLiikn0dn2mBF-jbkVlDd_kplGyTF1PZ8GScEgi2iPyOUW_GJtqR-dX_Uc64i1wY)Proceedings of the 2022 International Conference on Management of Data. 2022.


22. Zopf, Markus. [1-wl expressiveness is (almost) all you need.](https://ieeexplore.ieee.org/iel7/9891857/9889787/09892655.pdf?casa_token=5_mM3WQIkGkAAAAA:RQTTmfE01mZmeBm46VajJ5BpUHM3JwRE2EGwbbBWKYtZq3eOWTPo1USM8EhXTtPln82las2baNEH) 2022 International Joint Conference on Neural Networks (IJCNN). IEEE, 2022.


23. Yang, Mingqi, et al. [Breaking the expression bottleneck of graph neural networks.](https://ieeexplore.ieee.org/iel7/69/4358933/09759979.pdf?casa_token=4Rwcz_1CLtoAAAAA:tHV_d088q2NWfRb517eUeq2OQ6XB0a99lGg2gxlYe8Zsic97u9BAb9xqZx-2i3LilF7l5wL0y9t2) IEEE Transactions on Knowledge and Data Engineering (2022).


24. Bianchi, Filippo Maria, and Veronica Lachi. [The expressive power of pooling in Graph Neural Networks.](https://arxiv.org/pdf/2304.01575) arXiv preprint arXiv:2304.01575 (2023).


25. Feldman, Or, et al. [Weisfeiler and leman go infinite: Spectral and combinatorial pre-colorings.](https://arxiv.org/pdf/2201.13410) arXiv preprint arXiv:2201.13410 (2022).


26. Liu, Linfeng, et al. [Towards Accurate Subgraph Similarity Computation via Neural Graph Pruning.](https://arxiv.org/pdf/2210.10643) arXiv preprint arXiv:2210.10643 (2022).


27. Xia, Wenwen, Yuchen Li, and Shenghong Li. [On the Substructure Countability of Graph Neural Networks.](https://ieeexplore.ieee.org/iel7/69/4358933/09961144.pdf?casa_token=WlqXB0BXtgEAAAAA:dOrrBZeIjw75i2xnTH8E_kSSwgjWUS5Nf2pZizn9ZA0brdcAoHC4-GxtaJJkWznMt3aUh4gJPEI5) IEEE Transactions on Knowledge and Data Engineering (2022).


28. Beddar-Wiesing, Silvia, et al. [Weisfeiler--Lehman goes Dynamic: An Analysis of the Expressive Power of Graph Neural Networks for Attributed and Dynamic Graphs.](https://arxiv.org/pdf/2210.03990) arXiv preprint arXiv:2210.03990 (2022).


29. Wang, Zhaohui, et al. [Twin Weisfeiler-Lehman: High Expressive GNNs for Graph Classification.](https://arxiv.org/pdf/2203.11683) arXiv preprint arXiv:2203.11683 (2022).


30. Fang, Zhongxi, et al. [Wasserstein Graph Distance based on $ L_1 $-Approximated Tree Edit Distance between Weisfeiler-Lehman Subtrees.](https://arxiv.org/pdf/2207.04216) arXiv preprint arXiv:2207.04216 (2022).


31. Imaduwage, Sarith, P. P. N. V. Kumara, and W. J. Samaraweera. [The Mismatch between Graph Neural Networks’ Expressivity and Propagation Graphs in Fake News Detection.](https://ieeexplore.ieee.org/iel7/9900505/9900509/09900611.pdf?casa_token=nGYkd2AQtjYAAAAA:YDufZYwmiaLDYuXN8CXXyPU3naSBajuD3j8L7qcrbBOPvVGvp0SDgXCpe3D9lVUktyBZeceXT3SE) 2022 IEEE/ACIS 7th International Conference on Big Data, Cloud Computing, and Data Science (BCD). IEEE, 2022.


32. Murphy, Ryan L. [A Novel Framework for Invariant Neural Networks Applied to Graph and Set Data.](https://hammer.purdue.edu/ndownloader/files/27780936) Diss. Purdue University Graduate School, 2021.


33. Tahmasebi, Behrooz, and Stefanie Jegelka. [On the Effect of Input Perturbations for Graph Neural Networks.](https://openreview.net/pdf?id=TGfj2P_410X)


34. Tingyang, Yu. [Subgraph Sampling Strategy for Equivariant Subgraph Aggregation Network Based on Weisfeiler-Lehman Similarity.](https://yistyu.github.io/files/FYP_Thesis.pdf)


35. Azizian, Waiss, and Marc Lelarge. [Expressive power of invariant and equivariant graph neural networks.](https://arxiv.org/pdf/2006.15646) arXiv preprint arXiv:2006.15646 (2020).

36. Joshi, Chaitanya K., et al. [On the expressive power of geometric graph neural networks.](https://arxiv.org/pdf/2301.09308) arXiv preprint arXiv:2301.09308 (2023).


37. Balcilar, Muhammet, et al. [Analyzing the expressive power of graph neural networks in a spectral perspective.](https://hal-normandie-univ.archives-ouvertes.fr/hal-03135633/document) Proceedings of the International Conference on Learning Representations (ICLR). 2021.


38. Xu, Keyulu, et al. [How powerful are graph neural networks?.](https://arxiv.org/pdf/1810.00826) arXiv preprint arXiv:1810.00826 (2018).


39. Li, Pan, and Jure Leskovec. [The expressive power of graph neural networks.](https://graph-neural-networks.github.io/static/file/chapter5.pdf) Graph Neural Networks: Foundations, Frontiers, and Applications (2022): 63-98.


40. Wang, Xiyuan, and Muhan Zhang. [How powerful are spectral graph neural networks.](https://proceedings.mlr.press/v162/wang22am/wang22am.pdf) International Conference on Machine Learning. PMLR, 2022.


41. You, Jiaxuan, et al. [Identity-aware graph neural networks.](https://ojs.aaai.org/index.php/AAAI/article/download/17283/17090) Proceedings of the AAAI conference on artificial intelligence. Vol. 35. No. 12. 2021.


42. Feng, Jiarui, et al. [How powerful are k-hop message passing graph neural networks.](https://arxiv.org/pdf/2205.13328) arXiv preprint arXiv:2205.13328 (2022).


43. Balcilar, Muhammet, et al. [Breaking the limits of message passing graph neural networks.](http://proceedings.mlr.press/v139/balcilar21a/balcilar21a.pdf) International Conference on Machine Learning. PMLR, 2021.


44. Bouritsas, Giorgos, et al. [Improving graph neural network expressivity via subgraph isomorphism counting.](https://ieeexplore.ieee.org/iel7/34/4359286/09721082.pdf?casa_token=xImsEHd2j9YAAAAA:nN3egM4BulVgyNAaL-8UeVI61v8UBK1AoTuLbXdcN0F-S6BrxZAzILods4iRyPEZiPBn3miSj31_) IEEE Transactions on Pattern Analysis and Machine Intelligence 45.1 (2022): 657-668.


45. Papp, Pál András, et al. [DropGNN: Random dropouts increase the expressiveness of graph neural networks.](https://proceedings.neurips.cc/paper/2021/file/b8b2926bd27d4307569ad119b6025f94-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 21997-22009.


46. Liu, Songtao, et al. [Local augmentation for graph neural networks.](https://proceedings.mlr.press/v162/liu22s/liu22s.pdf) International Conference on Machine Learning. PMLR, 2022.


47. Kanatsoulis, Charilaos I., and Alejandro Ribeiro. [Graph neural networks are more powerful than we think.](https://arxiv.org/pdf/2205.09801) arXiv preprint arXiv:2205.09801 (2022).


48. Xu, Keyulu, et al. [Optimization of graph neural networks: Implicit acceleration by skip connections and more depth.](http://proceedings.mlr.press/v139/xu21k/xu21k.pdf) International Conference on Machine Learning. PMLR, 2021.


49. Du, Weitao, et al. [A new perspective on building efficient and expressive 3D equivariant graph neural networks.](https://arxiv.org/pdf/2304.04757) arXiv preprint arXiv:2304.04757 (2023).


50. Barceló, Pablo, et al. [The logical expressiveness of graph neural networks.](https://hal.science/hal-03356968/document) 8th International Conference on Learning Representations (ICLR 2020). 2020.


51. Guo, Alan JX, Qing-Hu Hou, and Ou Wu. [Improving the Expressive Power of Graph Neural Network with Tinhofer Algorithm.](https://arxiv.org/pdf/2104.01848) arXiv preprint arXiv:2104.01848 (2021).


52. Geerts, Floris. [The expressive power of kth-order invariant graph networks.](https://arxiv.org/pdf/2007.12035) arXiv preprint arXiv:2007.12035 (2020).


53. Bo, Deyu, et al. [A Survey on Spectral Graph Neural Networks.](https://arxiv.org/pdf/2302.05631) arXiv preprint arXiv:2302.05631 (2023).


54. Michel, Gaspard, et al. [Path Neural Networks: Expressive and Accurate Graph Neural Networks.](https://arxiv.org/pdf/2306.05955) arXiv preprint arXiv:2306.05955 (2023).


55. Aamand, Anders, et al. [Exponentially improving the complexity of simulating the Weisfeiler-Lehman test with graph neural networks.](https://proceedings.neurips.cc/paper_files/paper/2022/file/af0ad514b9cda46bd49e14ee11e2672f-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 27333-27346.

56. Geerts, Floris, and Juan L. Reutter. [Expressiveness and approximation properties of graph neural networks.](https://arxiv.org/pdf/2204.04661) arXiv preprint arXiv:2204.04661 (2022).


57. Maron, Haggai, et al. [Provably powerful graph networks.](https://proceedings.neurips.cc/paper/2019/file/bb04af0f7ecaee4aae62035497da1387-Paper.pdf) Advances in neural information processing systems 32 (2019).


58. Zhang, Muhan, and Pan Li. [Nested graph neural networks.](https://proceedings.neurips.cc/paper/2021/file/8462a7c229aea03dde69da754c3bbcc4-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 15734-15747.


59. Morris, Christopher, et al. [Speqnets: Sparsity-aware permutation-equivariant graph networks.](https://proceedings.mlr.press/v162/morris22a/morris22a.pdf) International Conference on Machine Learning. PMLR, 2022.


60. Villar, Soledad, et al. [Scalars are universal: Equivariant machine learning, structured like classical physics.](https://proceedings.neurips.cc/paper/2021/file/f1b0775946bc0329b35b823b86eeb5f5-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 28848-28863.

61. Cotta, Leonardo, Christopher Morris, and Bruno Ribeiro. [Reconstruction for powerful graph representations.](https://proceedings.neurips.cc/paper/2021/file/0d8080853a54f8985276b0130266a657-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 1713-1726.



62. Han, Jiaqi, et al. [Geometrically equivariant graph neural networks: A survey.](https://arxiv.org/pdf/2202.07230) arXiv preprint arXiv:2202.07230 (2022).


63. Morris, Christopher, et al. [Weisfeiler and leman go machine learning: The story so far.](https://arxiv.org/pdf/2112.09992) arXiv preprint arXiv:2112.09992 (2021).


64. Gao, Jianfei, and Bruno Ribeiro. [On the equivalence between temporal and static equivariant graph representations.](https://proceedings.mlr.press/v162/gao22e/gao22e.pdf) International Conference on Machine Learning. PMLR, 2022.


65. Huang, Zhongyu, et al. [Going Deeper into Permutation-Sensitive Graph Neural Networks.](https://proceedings.mlr.press/v162/huang22l/huang22l.pdf) International Conference on Machine Learning. PMLR, 2022.


66. Cai, Chen, and Yusu Wang. [Convergence of invariant graph networks.](https://proceedings.mlr.press/v162/cai22b/cai22b.pdf) International Conference on Machine Learning. PMLR, 2022.


67. Chen, Samantha, et al. [Weisfeiler-Lehman Meets Gromov-Wasserstein.](https://proceedings.mlr.press/v162/chen22o/chen22o.pdf) International Conference on Machine Learning. PMLR, 2022.


68.  Puny, Omri, et al. [Beddar-Wiesing, Silvia, et al. "Weisfeiler--Lehman goes Dynamic: An Analysis of the Expressive Power of Graph Neural Networks for Attributed and Dynamic Graphs." arXiv preprint arXiv:2210.03990 (2022). for graph neural networks.](https://arxiv.org/pdf/2302.11556) arXiv preprint arXiv:2302.11556 (2023).


69. Huang, Yinan, et al. [Boosting the Cycle Counting Power of Graph Neural Networks with I $^ 2$-GNNs.](https://arxiv.org/pdf/2210.13978) arXiv preprint arXiv:2210.13978 (2022).


70. Feng, Jiarui, et al. [Towards Arbitrarily Expressive GNNs in $ O (n^ 2) $ Space by Rethinking Folklore Weisfeiler-Lehman.](https://arxiv.org/pdf/2306.03266) arXiv preprint arXiv:2306.03266 (2023).

71. Böker, Jan, et al. [Fine-grained Expressivity of Graph Neural Networks.](https://arxiv.org/pdf/2306.03698) arXiv preprint arXiv:2306.03698 (2023).


72. Luo, Zhezheng, et al. [On the Expressiveness and Generalization of Hypergraph Neural Networks.](https://arxiv.org/pdf/2303.05490) arXiv preprint arXiv:2303.05490 (2023).


73. Zhang, Bohang, et al. [A Complete Expressiveness Hierarchy for Subgraph GNNs via Subgraph Weisfeiler-Lehman Tests.](https://arxiv.org/pdf/2302.07090) arXiv preprint arXiv:2302.07090 (2023).


74. Zhu, Wenhao, et al. [On Structural Expressive Power of Graph Transformers."](https://arxiv.org/pdf/2305.13987) arXiv preprint arXiv:2305.13987 (2023).

75. Liu, Chang, et al. [EDEN: A Plug-in Equivariant Distance Encoding to Beyond the 1-WL Test.](https://arxiv.org/pdf/2211.10739) arXiv preprint arXiv:2211.10739 (2022).

76. Le, Thien, and Stefanie Jegelka. [Limits, approximation and size transferability for GNNs on sparse graphs via graphops.](https://arxiv.org/pdf/2306.04495) arXiv preprint arXiv:2306.04495 (2023).

77. Mitton, Joshua, and Roderick Murray-Smith. [Subgraph Permutation Equivariant Networks.](https://arxiv.org/pdf/2111.11840) arXiv preprint arXiv:2111.11840 (2021).

78. Liu, Zhiyuan, et al. [Towards Equivariant Graph Contrastive Learning via Cross-Graph Augmentation.](https://openreview.net/pdf?id=ha9hPpthvQ) (2023).

79. Dasoulas, Georgios. [Towards Expressive Graph Neural Networks: Theory, Algorithms, and Applications.](https://theses.hal.science/tel-03666690/document) Diss. Institut Polytechnique de Paris, 2022.

80. Geerts, Floris, and Juan L. Reutter. [Expressiveness and approximation properties of graph neural networks.](https://arxiv.org/pdf/2204.04661) arXiv preprint arXiv:2204.04661 (2022).

81. Lim, Derek, et al. [Sign and basis invariant networks for spectral graph representation learning.](https://arxiv.org/pdf/2202.13013) arXiv preprint arXiv:2202.13013 (2022).

82. Morris, Christopher, et al. [Speqnets: Sparsity-aware permutation-equivariant graph networks.](https://proceedings.mlr.press/v162/morris22a/morris22a.pdf) International Conference on Machine Learning. PMLR, 2022.

83. Kong, Lecheng, Yixin Chen, and Muhan Zhang. [Geodesic Graph Neural Network for Efficient Graph Representation Learning.](https://arxiv.org/pdf/2210.02636) arXiv preprint arXiv:2210.02636 (2022).

### Geometric Graph Neural Networks, Topology and Lie Group

Many of the papers that bridges topology and equivariant graphNN that mentioned above.

1. Sahbi, Hichem. [Topologically-Consistent Magnitude Pruning for Very Lightweight Graph Convolutional Networks.](https://ieeexplore.ieee.org/document/9897899?denied=) 2022 IEEE International Conference on Image Processing (ICIP). IEEE, 2022.

2. Paolino, Raffaele, et al. [Unveiling the Sampling Density in Non-Uniform Geometric Graphs.](https://arxiv.org/pdf/2210.08219.pdf) arXiv preprint arXiv:2210.08219 (2022).

3. Sahbi, Hichem. [Lightweight Graph Convolutional Networks with Topologically Consistent Magnitude Pruning.](https://arxiv.org/pdf/2203.13616.pdf) arXiv preprint arXiv:2203.13616 (2022).

4. Feng, Fan, et al. [Community Channel-Net: Efficient channel-wise interactions via community graph topology.](https://www.sciencedirect.com/science/article/pii/S0031320323002364?casa_token=e_u4pwTRWtEAAAAA:7ndobj_IlridjrTekVfb8dCSTutommVNWdyrQ5lowg6WHVj7U-sy4GIOqh7PkvoAVMzboBJ2xYqO) Pattern Recognition 141 (2023): 109536.


5. Dehmamy, Nima, Albert-László Barabási, and Rose Yu. [Understanding the representation power of graph neural networks in learning graph topology.](https://proceedings.neurips.cc/paper/2019/file/73bf6c41e241e28b89d0fb9e0c82f9ce-Paper.pdf) Advances in Neural Information Processing Systems 32 (2019).


6. Gagrani, Mukul, et al. [Neural Topological Ordering for Computation Graphs.](https://proceedings.neurips.cc/paper_files/paper/2022/file/6ef586bdf0af0b609b1d0386a3ce0e4b-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 17327-17339.

7. Dehmamy, Nima, Albert-László Barabási, and Rose Yu. [Understanding the representation power of graph neural networks in learning graph topology.](https://proceedings.neurips.cc/paper/2019/file/73bf6c41e241e28b89d0fb9e0c82f9ce-Paper.pdf) Advances in Neural Information Processing Systems 32 (2019).

8. Ye, Xue, Fang Sun, and Shiming Xiang. [TREPH: A Plug-In Topological Layer for Graph Neural Networks.](https://www.mdpi.com/1099-4300/25/2/331/pdf) Entropy 25.2 (2023): 331.

9. Zheng, Shuai, et al. [Node-oriented Spectral Filtering for Graph Neural Networks.](https://arxiv.org/pdf/2212.03654) arXiv preprint arXiv:2212.03654 (2022).

10. Horn, Max, et al. [Topological graph neural networks.](https://arxiv.org/pdf/2102.07835) arXiv preprint arXiv:2102.07835 (2021).

11. Wei, Lanning, Huan Zhao, and Zhiqiang He. [Designing the topology of graph neural networks: A novel feature fusion perspective.](https://dl.acm.org/doi/pdf/10.1145/3485447.3512185) Proceedings of the ACM Web Conference 2022. 2022.

12. Liu, Shaohui, Chengyang Wu, and Hao Zhu. [Topology-aware graph neural networks for learning feasible and adaptive AC-OPF solutions.](https://ieeexplore.ieee.org/iel7/59/4374138/09992121.pdf) IEEE Transactions on Power Systems (2022).

13. Zhang, Jiying, et al. [Fine-tuning graph neural networks via graph topology induced optimal transport.](https://arxiv.org/pdf/2203.10453) arXiv preprint arXiv:2203.10453 (2022).

14. Southern, Joshua, et al. [Curvature filtrations for graph generative model evaluation.](https://arxiv.org/pdf/2301.12906) arXiv preprint arXiv:2301.12906 (2023).

15. Zhang, Simon, Soham Mukherjee, and Tamal K. Dey. [GEFL: Extended Filtration Learning for Graph Classification.](https://proceedings.mlr.press/v198/zhang22b/zhang22b.pdf) Learning on Graphs Conference. PMLR, 2022.

16. Xu, Jiaxing, et al. [Union Subgraph Neural Networks.](https://arxiv.org/pdf/2305.15747) arXiv preprint arXiv:2305.15747 (2023).

17. Chen, Yuzhou, Elena Sizikova, and Yulia R. Gel. [TopoAttn-Nets: Topological Attention in Graph Representation Learning.](https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_1052.pdf) Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer International Publishing, 2022.

18. Gao, He, et al. [Topological Graph Convolutional Network Based on Complex Network Characteristics.](https://ieeexplore.ieee.org/iel7/6287639/9668973/09795303.pdf) IEEE Access 10 (2022): 64465-64472.

19. Horoi, Stefan, et al. [Exploring the geometry and topology of neural network loss landscapes.](https://arxiv.org/pdf/2102.00485) Advances in Intelligent Data Analysis XX: 20th International Symposium on Intelligent Data Analysis, IDA 2022, Rennes, France, April 20–22, 2022, Proceedings. Cham: Springer International Publishing, 2022.

20. Rieck, Bastian. [On the Expressivity of Persistent Homology in Graph Learning.](https://arxiv.org/pdf/2302.09826) arXiv preprint arXiv:2302.09826 (2023).

21. Aktas, Mehmet Emin, Thu Nguyen, and Esra Akbas. [Homology Preserving Graph Compression.](https://ieeexplore.ieee.org/iel7/9679834/9679948/09680010.pdf) 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2021.

22. Bamberger, Jacob. [A Topological characterisation of Weisfeiler-Leman equivalence classes.](https://proceedings.mlr.press/v196/bamberger22a/bamberger22a.pdf) Topological, Algebraic and Geometric Learning Workshops 2022. PMLR, 2022.

23. Xin, Cheng, et al. [A $2 $-parameter Persistence Layer for Learning.](https://openreview.net/pdf?id=WF7dU23lRCo) (2023).

24. Segovia-Dominguez, Ignacio, et al. [EMP: Effective Multidimensional Persistence for Graph Representation Learning.](https://openreview.net/pdf?id=pBaSwBkHBE) (2023).

25. Satorras, Vıctor Garcia, Emiel Hoogeboom, and Max Welling. [E (n) equivariant graph neural networks.](http://proceedings.mlr.press/v139/satorras21a/satorras21a.pdf) International conference on machine learning. PMLR, 2021.

*26. Stärk, Hannes, et al. [Equibind: Geometric deep learning for drug binding structure prediction.](https://proceedings.mlr.press/v162/stark22b/stark22b.pdf) International Conference on Machine Learning. PMLR, 2022.

27. Liu, Shengchao, et al. [Pre-training molecular graph representation with 3d geometry.](https://arxiv.org/pdf/2110.07728) arXiv preprint arXiv:2110.07728 (2021).

28. Villar, Soledad, et al. [Scalars are universal: Equivariant machine learning, structured like classical physics.](https://proceedings.neurips.cc/paper/2021/file/f1b0775946bc0329b35b823b86eeb5f5-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 28848-28863.

29. Satorras, Victor Garcia, et al. [E (n) equivariant normalizing flows.](https://arxiv.org/pdf/2105.09016) arXiv preprint arXiv:2105.09016 (2021).

30. Ganea, Octavian-Eugen, et al. [Independent se (3)-equivariant models for end-to-end rigid protein docking.](https://arxiv.org/pdf/2111.07786.pdf?trk=public_post_comment-text) arXiv preprint arXiv:2111.07786 (2021).

31. Brandstetter, Johannes, et al. [Geometric and physical quantities improve e (3) equivariant message passing.](https://arxiv.org/pdf/2110.02905) arXiv preprint arXiv:2110.02905 (2021).

32. Gasteiger, Johannes, Chandan Yeshwanth, and Stephan Günnemann. [Directional message passing on molecular graphs via synthetic coordinates.](https://proceedings.neurips.cc/paper/2021/file/82489c9737cc245530c7a6ebef3753ec-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 15421-15433.

33. Shuaibi, Muhammed, et al. [Rotation invariant graph neural networks using spin convolutions.](https://arxiv.org/pdf/2106.09575) arXiv preprint arXiv:2106.09575 (2021).

34. Bogatskiy, Alexander, et al. [Symmetry group equivariant architectures for physics.](https://arxiv.org/pdf/2203.06153) arXiv preprint arXiv:2203.06153 (2022).


### Graph Neural Networks & Algorithms on solving NP-hard problems
From my observation, SAT is the most researhed topicm then TSP, CNF, DNF, and coloring. May be overlapped with some of the spectral methods with aim of graph approximations.

1. Prates, Marcelo, et al. [Learning to solve np-complete problems: A graph neural network for decision tsp.](https://arxiv.org/pdf/1809.02721.pdf) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. No. 01. 2019.

2. Cappart, Quentin, et al. [Combinatorial optimization and reasoning with graph neural networks.](https://arxiv.org/pdf/2102.09544.pdf) arXiv preprint arXiv:2102.09544 (2021).

3. Xing, Zhihao, and Shikui Tu. [A graph neural network assisted monte carlo tree search approach to traveling salesman problem.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109309) IEEE Access 8 (2020): 108418-108428. 

4. Hu, Yujiao, et al. [A bidirectional graph neural network for traveling salesman problems on arbitrary symmetric graphs.](https://www.sciencedirect.com/science/article/pii/S0952197620303286?casa_token=ZKx0vZrQFfMAAAAA:4eGQeASYSx6wqvM10bZyt0nX9FsbDexYigpxpOJO7QLj_lNYVlyotlwwDi7p4ilcCIGRHRYr88rK) Engineering Applications of Artificial Intelligence 97 (2021): 104061.

5. Abboud, Ralph, Ismail Ceylan, and Thomas Lukasiewicz. [Learning to reason: Leveraging neural networks for approximate DNF counting.](https://ojs.aaai.org/index.php/AAAI/article/view/5705/5561) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.

6. Yow, Kai Siong, and Siqiang Luo. [Learning-based approaches for graph problems: a survey.](https://arxiv.org/pdf/2204.01057.pdf) arXiv preprint arXiv:2204.01057 (2022).

7. Liu, Minghao, et al. [Can Graph Neural Networks Learn to Solve MaxSAT Problem?.](https://arxiv.org/pdf/2111.07568.pdf) arXiv preprint arXiv:2111.07568 (2021).

8. Selsam, Daniel, et al. [Learning a SAT solver from single-bit supervision.](https://arxiv.org/pdf/1802.03685.pdf) arXiv preprint arXiv:1802.03685 (2018).

9. Kothapalli, Abihith, Mudassir Shabbir, and Xenofon Koutsoukos. [Learning-Based Heuristic for Combinatorial Optimization of the Minimum Dominating Set Problem using Graph Convolutional Networks.](https://arxiv.org/pdf/2306.03434.pdf) arXiv preprint arXiv:2306.03434 (2023).

10. Liu, Minghao, et al. [Learning the satisfiability of pseudo-Boolean problem with graph neural networks.](https://link.springer.com/chapter/10.1007/978-3-030-58475-7_51) Principles and Practice of Constraint Programming: 26th International Conference, CP 2020, Louvain-la-Neuve, Belgium, September 7–11, 2020, Proceedings 26. Springer International Publishing, 2020.


11. Panagopoulos, George, et al. [Learning Graph Representations for Influence Maximization.](https://arxiv.org/pdf/2108.04623.pdf) arXiv preprint arXiv:2108.04623 (2021).

12. Lamb, Luis C., et al. [Graph neural networks meet neural-symbolic computing: A survey and perspective.](https://arxiv.org/pdf/2003.00330.pdf) arXiv preprint arXiv:2003.00330 (2020).

13. Joshi, Chaitanya K., et al. [Learning TSP requires rethinking generalization.](https://drops.dagstuhl.de/opus/volltexte/2021/15324/pdf/LIPIcs-CP-2021-33.pdf) 27th International Conference on Principles and Practice of Constraint Programming (CP 2021). Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2021.

14. Yolcu, Emre, and Barnabás Póczos. [Learning local search heuristics for boolean satisfiability.](https://proceedings.neurips.cc/paper/2019/file/12e59a33dea1bf0630f46edfe13d6ea2-Paper.pdf) Advances in Neural Information Processing Systems 32 (2019).  (SAT)

15. Joshi, Chaitanya K., et al. [Learning the travelling salesperson problem requires rethinking generalization.](https://link.springer.com/article/10.1007/s10601-022-09327-y) Constraints 27.1-2 (2022): 70-98.

16. Kurin, Vitaly, et al. [Can Q-learning with graph networks learn a generalizable branching heuristic for a SAT solver?.](https://proceedings.neurips.cc/paper/2020/file/6d70cb65d15211726dcce4c0e971e21c-Paper.pdf) Advances in Neural Information Processing Systems 33 (2020): 9608-9621.


17. Zhang, Wenjie, et al. [NLocalSAT: Boosting local search with solution prediction.](https://arxiv.org/pdf/2001.09398) arXiv preprint arXiv:2001.09398 (2020).

18. Zhang, Lisa, et al. [Neural guided constraint logic programming for program synthesis.](https://proceedings.neurips.cc/paper/2018/file/67d16d00201083a2b118dd5128dd6f59-Paper.pdf) Advances in Neural Information Processing Systems 31 (2018).

19. Abdelaziz, Ibrahim, et al. [Learning to guide a saturation-based theorem prover.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669114&casa_token=uaofxFc5dUEAAAAA:zgqvtqcP8gxwPT_xmyxwoRfProT2EhPPc2vwQ_BNicsOEt22geofLCOlre8TKv_NIgIF0IMXm5Su) IEEE Transactions on Pattern Analysis and Machine Intelligence 45.1 (2022): 738-751.

20. Angelini, Maria Chiara, and Federico Ricci-Tersenghi. [Cracking nuts with a sledgehammer: when modern graph neural networks do worse than classical greedy algorithms.](https://arxiv.org/pdf/2206.13211) arXiv preprint arXiv:2206.13211 (2022).

21. Tönshoff, Jan, et al. [One model, any CSP: Graph neural networks as fast global search heuristics for constraint satisfaction.](https://arxiv.org/pdf/2208.10227) arXiv preprint arXiv:2208.10227 (2022).

22. Yang, Lei, and Lei Zou. [Noah: Neural-optimized A Search Algorithm for Graph Edit Distance Computation.](https://ieeexplore.ieee.org/iel7/9458599/9458600/09458863.pdf?casa_token=nwHBBJEdHXUAAAAA:IeLY-bojxj2mGYrWEVmb0gYxjKs-C4HMYQ19N2FWH-mpN09w9KzUZznWBbLqu6NQ_dDDeAmj3zO3) 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEE, 2021.

23. Wang, Wenxi, et al. [NeuroComb: Improving SAT Solving with Graph Neural Networks.](https://arxiv.org/pdf/2110.14053) arXiv preprint arXiv:2110.14053 (2021).

24. Liu, Minghao, et al. [Can Graph Neural Networks Learn to Solve MaxSAT Problem?.](https://arxiv.org/pdf/2111.07568) arXiv preprint arXiv:2111.07568 (2021).

25. Grötschla, Florian, Joël Mathys, and Roger Wattenhofer. [Learning Graph Algorithms With Recurrent Graph Neural Networks.](https://arxiv.org/pdf/2212.04934) arXiv preprint arXiv:2212.04934 (2022).

26. Glorot, Xavier, et al. [Learning representations of logical formulae using graph neural networks.](https://grlearning.github.io/papers/58.pdf) Neural Information Processing Systems, Workshop on Graph Representation Learning. 2019.

27. Saveri, Gaia, and Luca Bortolussi. [Graph Neural Networks for Propositional Model Counting.](https://arxiv.org/pdf/2205.04423) arXiv preprint arXiv:2205.04423 (2022).

28. Zhang, Congsong, Yong Gao, and James Nastos. [Learning Branching Heuristics from Graph Neural Networks.](https://arxiv.org/pdf/2211.14405) arXiv preprint arXiv:2211.14405 (2022).

29. Sun, Changzhi, et al. [Probabilistic graph reasoning for natural proof generation.](https://arxiv.org/pdf/2107.02418) arXiv preprint arXiv:2107.02418 (2021).

30. Chen, Ziliang, and Zhanfu Yang. [Graph neural reasoning may fail in certifying boolean unsatisfiability.](https://arxiv.org/pdf/1909.11588) arXiv preprint arXiv:1909.11588 (2019).

31. Yan, Zhiyuan, et al. [Addressing Variable Dependency in GNN-based SAT Solving.](https://arxiv.org/pdf/2304.08738) arXiv preprint arXiv:2304.08738 (2023).

32. Mukherjee, Prasita, and Tiark Rompf. [A GNN Based Approach to LTL Model Checking.](https://arxiv.org/pdf/2110.14824) arXiv preprint arXiv:2110.14824 (2021).

33. Xu, Feifan, et al. [Fast OBDD reordering using neural message passing on hypergraph.](https://arxiv.org/pdf/1811.02178) arXiv preprint arXiv:1811.02178 (2018).

34. Malmqvist, Lars. [Approximate Solutions to Abstract Argumentation Problems Using Graph Neural Networks.](https://etheses.whiterose.ac.uk/32152/6/thesis.pdf) Diss. University of York, 2022.

35. Hagström, Fredrik, and Fredrik Hagström. [Finding Solutions to the Vehicle Routing Problem using a Graph Neural Network.](https://sal.aalto.fi/publications/pdf-files/theses/bac/thag22_public.pdf) (2022).

36. Ghose, Amur, Amit Levi, and Yingxue Zhang. [Graph neural networks for Ramsey graphs.](https://mathai2022.github.io/papers/18.pdf)

37. Hula, Jan, David Mojzıšek, and Mikoláš Janota. [Towards Graph Neural Networks for SMT Portfolios.](http://aitp-conference.org/2021/abstract/paper_27.pdf)

38. Amizadeh, Saeed, Sergiy Matusevych, and Markus Weimer. [PDP: A General Neural Framework for Learning SAT Solvers.](https://openreview.net/pdf?id=S1xaf6VFPB)

39. de Aquino Afonso, Bruno Klaus, et al. [Kdd-br 2021: Using graph neural networks for link prediction in tsp problem.](https://sol.sbc.org.br/index.php/eniac/article/download/18426/18259/) Anais do XVIII Encontro Nacional de Inteligência Artificial e Computacional. SBC, 2021.

40. Hudson, Benjamin, et al. [Graph neural network guided local search for the traveling salesperson problem.](https://arxiv.org/pdf/2110.05291) arXiv preprint arXiv:2110.05291 (2021).

41. Feldman, Or, et al. [Weisfeiler and leman go infinite: Spectral and combinatorial pre-colorings.](https://arxiv.org/pdf/2201.13410) arXiv preprint arXiv:2201.13410 (2022).

### Spectral Graph Theories, Laplacian Approximations  & Combinatorical Optimization with GNN

1. Cappart, Quentin, et al. [Combinatorial optimization and reasoning with graph neural networks.](https://arxiv.org/pdf/2102.09544.pdf) arXiv preprint arXiv:2102.09544 (2021).

2. Yadati, Naganand, et al. [Hypergcn: A new method for training graph convolutional networks on hypergraphs.](https://proceedings.neurips.cc/paper/2019/file/1efa39bcaec6f3900149160693694536-Paper.pdf) Advances in neural information processing systems 32 (2019).

3. Peng, Yun, Byron Choi, and Jianliang Xu. [Graph learning for combinatorial optimization: a survey of state-of-the-art.](https://link.springer.com/article/10.1007/s41019-021-00155-3) Data Science and Engineering 6.2 (2021): 119-141.

4. Sahbi, Hichem. [Learning laplacians in chebyshev graph convolutional networks.](https://openaccess.thecvf.com/content/ICCV2021W/DLGC/papers/Sahbi_Learning_Laplacians_in_Chebyshev_Graph_Convolutional_Networks_ICCVW_2021_paper.pdf) Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.

5. Duan, Haonan, et al. [Augment with care: Contrastive learning for combinatorial problems.](https://proceedings.mlr.press/v162/duan22b/duan22b.pdf) International Conference on Machine Learning. PMLR, 2022.

6. Yan, Junchi, Shuang Yang, and Edwin R. Hancock. [Learning for graph matching and related combinatorial optimization problems.](https://eprints.whiterose.ac.uk/160087/1/MLGM_SVY_IJCAI20_Review_14_1.pdf) Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20. International Joint Conferences on Artificial Intelligence Organization, 2020.

7. Kuck, Jonathan, et al. [Belief propagation neural networks.](https://proceedings.neurips.cc/paper/2020/file/07217414eb3fbe24d4e5b6cafb91ca18-Paper.pdf) Advances in Neural Information Processing Systems 33 (2020): 667-678.

8. Sun, Haoran, Etash K. Guha, and Hanjun Dai. [Annealed Training for Combinatorial Optimization on Graphs.](https://arxiv.org/pdf/2207.11542.pdf) arXiv preprint arXiv:2207.11542 (2022).

9. Lee, Mengyuan, et al. [A fast graph neural network-based method for winner determination in multi-unit combinatorial auctions.](https://ieeexplore.ieee.org/abstract/document/9305731?casa_token=-UWqlkJx6L8AAAAA:s3eHHNJQMb532fF3ouyCKcs04p5_5QRPxu0AfvcIOk7frrPaQ8MFgdl4pVY3uzRIXF_JXDBKUvwu) IEEE Transactions on Cloud Computing 10.4 (2020): 2264-2280.

10. Gatti, Alice, et al. [Graph Partitioning and Sparse Matrix Ordering using Reinforcement Learning and Graph Neural Networks.](https://www.jmlr.org/papers/volume23/21-0644/21-0644.pdf) Journal of Machine Learning Research 23.303 (2022): 1-28.

11. Jovanovic, Raka, et al. [Applying graph neural networks to the decision version of graph combinatorial optimization problems.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103886) IEEE Access (2023).

12. Li, Zhuwen, Qifeng Chen, and Vladlen Koltun. [Combinatorial optimization with graph convolutional networks and guided tree search.](https://proceedings.neurips.cc/paper/2018/file/8d3bba7425e7c98c50f52ca1b52d3735-Paper.pdf) Advances in neural information processing systems 31 (2018).

13. Gasse, Maxime, et al. [Exact combinatorial optimization with graph convolutional neural networks.](https://proceedings.neurips.cc/paper/2019/file/d14c2267d848abeb81fd590f371d39bd-Paper.pdf) Advances in neural information processing systems 32 (2019).

14. Vesselinova, Natalia, et al. [Learning combinatorial optimization on graphs: A survey with applications to networking.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125934) IEEE Access 8 (2020): 120388-120416.

15. Drori, Iddo, et al. [Learning to solve combinatorial optimization problems on real-world graphs in linear time.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356192&casa_token=Oi5pcBrVZXsAAAAA:tU7zH7gVr30gu9t-4Ake0J7kSSQPakVjGU6l-Z-GsNSOHFG9uYamA_2y08921AORYhF0wjptXHxO) 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2020.

16. Luz, Ilay, et al. [Learning algebraic multigrid using graph neural networks.](http://proceedings.mlr.press/v119/luz20a/luz20a.pdf) International Conference on Machine Learning. PMLR, 2020.

17. Khalil, Elias B., Christopher Morris, and Andrea Lodi. [Mip-gnn: A data-driven framework for guiding combinatorial solvers.](https://ojs.aaai.org/index.php/AAAI/article/download/21262/21011) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 9. 2022.

18. Ju, Haotian, et al. [Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion.](https://proceedings.mlr.press/v206/ju23a/ju23a.pdf) International Conference on Artificial Intelligence and Statistics. PMLR, 2023.

19. Angelini, Maria Chiara, and Federico Ricci-Tersenghi. [Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set.](https://www.nature.com/articles/s42256-022-00589-y) Nature Machine Intelligence 5.1 (2023): 29-31.


20. Khalil, Elias, et al. [Learning combinatorial optimization algorithms over graphs.](https://proceedings.neurips.cc/paper/2017/file/d9896106ca98d3d05b8cbdf4fd8b13a1-Paper.pdf) Advances in neural information processing systems 30 (2017).

21. Schuetz, Martin JA, J. Kyle Brubaker, and Helmut G. Katzgraber. [Combinatorial optimization with physics-inspired graph neural networks.](https://idp.nature.com/authorize/casa?redirect_uri=https://www.nature.com/articles/s42256-022-00468-6&casa_token=zl7d4n7kUvwAAAAA:dSRgWyzdym4z_LMavvGfjdpoGZqhRd4FRtsNKV-uSz7DIlcgFofAY4GHLnIGIxLPOEpGAgMYe2-nup3AuBI) Nature Machine Intelligence 4.4 (2022): 367-377.


22. Chen, Ziang, et al. [On representing linear programs by graph neural networks.](https://arxiv.org/pdf/2209.12288) arXiv preprint arXiv:2209.12288 (2022).


23. D'Inverno, Giuseppe Alessio, et al. [A new perspective on the approximation capability of GNNs.](https://arxiv.org/pdf/2106.08992) arXiv preprint arXiv:2106.08992 (2021).

24. Balcilar, Muhammet, et al. [Analyzing the expressive power of graph neural networks in a spectral perspective.](https://hal-normandie-univ.archives-ouvertes.fr/hal-03135633/document) Proceedings of the International Conference on Learning Representations (ICLR). 2021.


25. Bo, Deyu, et al. [A Survey on Spectral Graph Neural Networks.](https://arxiv.org/pdf/2302.05631) arXiv preprint arXiv:2302.05631 (2023).


### Gradient Descent & Error Bounds on Graph Neural Networks (Convex/Concave)


1. Izadi, Mohammad Rasool, et al. [Optimization of graph neural networks with natural gradient descent.](https://arxiv.org/pdf/2008.09624) 2020 IEEE international conference on big data (big data). IEEE, 2020.

2. Awasthi, Pranjal, Abhimanyu Das, and Sreenivas Gollapudi. [A Convergence Analysis of Gradient Descent on Graph Neural Networks.](https://proceedings.neurips.cc/paper/2021/file/aaf2979785deb27864047e0ea40ef1b7-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 20385-20397.

3. Lee, Junghyun, et al. [A Statistical Analysis of Stochastic Gradient Noises for GNNs.](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11113553) 한국정보과학회 학술발표논문집 (2022): 1025-1027.

4. Li, Qunwei, Shaofeng Zou, and Wenliang Zhong. [Learning graph neural networks with approximate gradient descent.](https://ojs.aaai.org/index.php/AAAI/article/download/17025/16832) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 10. 2021.

5. Yadati, Naganand. [A Convex Formulation for Graph Convolutional Training: Two Layer Case.](https://ieeexplore.ieee.org/abstract/document/10027696/) 2022 IEEE International Conference on Data Mining (ICDM). IEEE, 2022.

6. Park, Junyoung, Chihyeon Song, and Jinkyoo Park. [Input Convex Graph Neural Networks: An Application to Optimal Control and Design Optimization.](https://openreview.net/forum?id=S2pNPZM-w-f)

7. Xu, Keyulu, et al. [Optimization of graph neural networks: Implicit acceleration by skip connections and more depth.](http://proceedings.mlr.press/v139/xu21k/xu21k.pdf) International Conference on Machine Learning. PMLR, 2021.


# Graph Representation Learning on Theoretical Natural Sciences


### Particle Physics
Almost all the papers are from this [link](https://iml-wg.github.io/HEPML-LivingReview/).

1. Hao, Zhongkai, et al. [Physics-Informed Machine Learning: A Survey on Problems, Methods and Applications.](https://arxiv.org/pdf/2211.08064) arXiv preprint arXiv:2211.08064 (2022).

2. Henrion, Isaac, et al. [Neural message passing for jet physics.](https://orbi.uliege.be/bitstream/2268/226446/1/nips_dlps_2017_29.pdf) (2017).

3. Ju, Xiangyang, et al. [Graph neural networks for particle reconstruction in high energy physics detectors.](https://arxiv.org/pdf/2003.11603) arXiv preprint arXiv:2003.11603 (2020).

4. Abdughani, Murat, et al. [Probing stop pair production at the LHC with graph neural networks.](https://link.springer.com/content/pdf/10.1007/JHEP08(2019)055.pdf) Journal of High Energy Physics 2019.8 (2019): 1-14.

5. Martínez, J. Arjona, et al. [Pileup mitigation at the Large Hadron Collider with graph neural networks.](https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1140/epjp/i2019-12710-3.pdf&casa_token=SP8PSdhh_CoAAAAA:HtQpQGe2oMSc4nwt0Y-l0KN1rR2p1X1cD-DKcQtHli8sZ6qoApfz6A_F86Bj0CTDd3IEglaaZMxi8CzJSQY) The European Physical Journal Plus 134.7 (2019): 333.

6. Ren, Jie, Lei Wu, and Jin Min Yang. [Unveiling CP property of top-Higgs coupling with graph neural networks at the LHC.](https://www.sciencedirect.com/science/article/pii/S0370269320300022) Physics Letters B 802 (2020): 135198.

7. Moreno, Eric A., et al. [JEDI-net: a jet identification algorithm based on interaction networks.](https://link.springer.com/article/10.1140/epjc/s10052-020-7608-4) The European Physical Journal C 80 (2020): 1-15.

8. Qasim, Shah Rukh, et al. [Learning representations of irregular particle-detector geometry with distance-weighted graph networks.](https://link.springer.com/article/10.1140/epjc/s10052-019-7113-9) The European Physical Journal C 79.7 (2019): 1-11.

9. Chakraborty, Amit, et al. [Neural network-based top tagger with two-point energy correlations and geometry of soft emissions.](https://link.springer.com/article/10.1007/JHEP07(2020)111) Journal of High Energy Physics 2020.7 (2020): 1-47.

10.  Abdughani, Murat, et al. [Probing the triple Higgs boson coupling with machine learning at the LHC.](https://link.aps.org/pdf/10.1103/PhysRevD.104.056003) Physical Review D 104.5 (2021): 056003.

11. Bernreuther, Elias, et al. [Casting a graph net to catch dark showers.](https://www.scipost.org/SciPostPhys.10.2.046/pdf) SciPost Physics 10.2 (2021): 046.

12. Shlomi, Jonathan, Peter Battaglia, and Jean-Roch Vlimant. [Graph neural networks in particle physics.](https://iopscience.iop.org/article/10.1088/2632-2153/abbf9a/pdf) Machine Learning: Science and Technology 2.2 (2020): 021001.

13. Iiyama, Yutaro, et al. [Distance-weighted graph neural networks on FPGAs for real-time particle reconstruction in high energy physics.](https://www.frontiersin.org/articles/10.3389/fdata.2020.598927/full) Frontiers in big Data 3 (2021): 598927.

14. Choma, Nicholas, et al. [Track seeding and labelling with embedded-space graph neural networks.](https://arxiv.org/pdf/2007.00149) arXiv preprint arXiv:2007.00149 (2020).

15. Guo, Jun, et al. [Boosted Higgs boson jet reconstruction via a graph neural network.](https://link.aps.org/pdf/10.1103/PhysRevD.103.116025) Physical Review D 103.11 (2021): 116025.

16. Verma, Yogesh, and Satyajit Jena. [Particle Track Reconstruction using Geometric Deep Learning.](https://arxiv.org/pdf/2012.08515) arXiv preprint arXiv:2012.08515 (2020).

17. Qian, Zhen, et al. [Vertex and energy reconstruction in JUNO with machine learning methods.](https://www.sciencedirect.com/science/article/pii/S016890022100512X?casa_token=iSHJwPiNg-QAAAAA:jkHR6CB7WxQ7ZuLN7TC7AYRIz_V1jM3Dy_-zwVaRuo9u_p2hPQv2BIkOvZXngWGF3Rhu5dRnPjlo) Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment 1010 (2021): 165527.

18. Pata, Joosep, et al. [MLPF: efficient machine-learned particle-flow reconstruction using graph neural networks.](https://link.springer.com/article/10.1140/epjc/s10052-021-09158-w) The European Physical Journal C 81 (2021): 1-14.

19. Biscarat, Catherine, et al. [Towards a realistic track reconstruction algorithm based on graph neural networks for the HL-LHC.](https://www.epj-conferences.org/articles/epjconf/pdf/2021/05/epjconf_chep2021_03047.pdf) EPJ Web of Conferences. Vol. 251. EDP Sciences, 2021.

20. Thais, Savannah, and Gage DeZoort. [Instance Segmentation Gnns for One-Shot Conformal Tracking at the LHC.](https://arxiv.org/pdf/2103.06509) arXiv preprint arXiv:2103.06509 (2021).

21. Verma, Yogesh, and Satyajit Jena. [Jet characterization in Heavy Ion Collisions by QCD-Aware Graph Neural Networks.](https://arxiv.org/pdf/2103.14906) arXiv preprint arXiv:2103.14906 (2021).

22. Hariri, Ali, Darya Dyachkova, and Sergei Gleyzer. [Graph generative models for fast detector simulations in high energy physics.](https://arxiv.org/pdf/2104.01725) arXiv preprint arXiv:2104.01725 (2021).

23. Konar, Partha, Vishal S. Ngairangbam, and Michael Spannowsky. [Energy-weighted message passing: an infra-red and collinear safe graph neural network algorithm.](https://link.springer.com/content/pdf/10.1007/JHEP02(2022)060.pdf) Journal of High Energy Physics 2022.2 (2022): 1-30.

24. Tsan, Steven, et al. [Particle Graph Autoencoders and Differentiable, Learned Energy Mover's Distance.](https://arxiv.org/pdf/2111.12849) arXiv preprint arXiv:2111.12849 (2021).

25. Gong, Shiqi, et al. [An efficient Lorentz equivariant graph neural network for jet tagging.](https://link.springer.com/content/pdf/10.1007/JHEP07(2022)030.pdf) Journal of High Energy Physics 2022.7 (2022): 1-22.

26. Qasim, Shah Rukh, et al. [End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks.](https://link.springer.com/article/10.1140/epjc/s10052-022-10665-7) The European Physical Journal C 82.8 (2022): 753.

27. Ma, Fei, Feiyi Liu, and Wei Li. [A jet tagging algorithm of graph network with HaarPooling message passing.](https://arxiv.org/pdf/2210.13869) arXiv preprint arXiv:2210.13869 (2022).

28. Bogatskiy, Alexander, et al. [PELICAN: Permutation Equivariant and Lorentz Invariant or Covariant Aggregator Network for Particle Physics.](https://arxiv.org/pdf/2211.00454) arXiv preprint arXiv:2211.00454 (2022).

29. Di Bello, Francesco Armando, et al. [Reconstructing particles in jets using set transformer and hypergraph prediction networks.](https://arxiv.org/pdf/2212.01328) arXiv preprint arXiv:2212.01328 (2022).

30. Ehrke, Lukas, et al. [Topological Reconstruction of Particle Physics Processes using Graph Neural Networks.](https://arxiv.org/pdf/2303.13937) arXiv preprint arXiv:2303.13937 (2023).

### Theoretical Biochemistry
There are huge amounts of GNN works done in this domain. Here we extract some important works for quick references, including molecule, drug, protein, retrosynthesis and single cell RNA seq.

1. Gilmer, Justin, et al. [Neural message passing for quantum chemistry.](http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf) International conference on machine learning. PMLR, 2017.

2. Thölke, Philipp, and Gianni De Fabritiis. [Equivariant transformers for neural network based molecular potentials.](https://openreview.net/pdf?id=zNHzqZ9wrRB) International Conference on Learning Representations. 2022.

3. Schütt, Kristof, et al. [Schnet: A continuous-filter convolutional neural network for modeling quantum interactions.](https://proceedings.neurips.cc/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf) Advances in neural information processing systems 30 (2017).

4. Feinberg, Evan N., et al. [PotentialNet for molecular property prediction.](https://pubs.acs.org/doi/pdf/10.1021/acscentsci.8b00507) ACS central science 4.11 (2018): 1520-1530.

5. Lu, Chengqiang, et al. [Molecular property prediction: A multilevel quantum interactions modeling perspective.](https://ojs.aaai.org/index.php/AAAI/article/download/3896/3774) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. No. 01. 2019.

6. You, Jiaxuan, et al. [Graph convolutional policy network for goal-directed molecular graph generation.](https://proceedings.neurips.cc/paper/2018/file/d60678e8f2ba9c540798ebbde31177e8-Paper.pdf) Advances in neural information processing systems 31 (2018).

7. Mercado, Rocío, et al. [Graph networks for molecular design.](https://iopscience.iop.org/article/10.1088/2632-2153/abcf91/pdf) Machine Learning: Science and Technology 2.2 (2021): 025023.

8. Liu, Qi, et al. [Constrained graph variational autoencoders for molecule design.](https://proceedings.neurips.cc/paper/2018/file/b8a03c5c15fcfa8dae0b03351eb1742f-Paper.pdf) Advances in neural information processing systems 31 (2018).

9. Liu, Shengchao, Hongyu Guo, and Jian Tang. [Molecular geometry pretraining with se (3)-invariant denoising distance matching.](https://arxiv.org/pdf/2206.13602) arXiv preprint arXiv:2206.13602 (2022).

10. Wang, Juexin, et al. [scGNN is a novel graph neural network framework for single-cell RNA-Seq analyses.](https://www.nature.com/articles/s41467-021-22197-x) Nature communications 12.1 (2021): 1882.

11. Gu, Haocheng, et al. [scGNN 2.0: a graph neural network tool for imputation and clustering of single-cell RNA-Seq data.](https://u.osu.edu/bmbl/files/2022/10/btac684.pdf) Bioinformatics 38.23 (2022): 5322-5325.

12. Gan, Yanglan, et al. [Deep structural clustering for single-cell RNA-seq data jointly through autoencoder and graph neural network.](https://academic.oup.com/bib/article/23/2/bbac018/6529282) Briefings in Bioinformatics 23.2 (2022).

13. Wen, Hongzhi, et al. [Graph neural networks for multimodal single-cell data integration.](https://arxiv.org/pdf/2203.01884) Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022.

14. Shao, Xin, et al. [scDeepSort: a pre-trained cell-type annotation method for single-cell transcriptomics using deep learning with a weighted graph neural network.](https://academic.oup.com/nar/article/49/21/e122/6368052) Nucleic acids research 49.21 (2021): e122-e122.

15. Zeng, Yuansong, et al. [A robust and scalable graph neural network for accurate single-cell classification.](https://www.biorxiv.org/content/biorxiv/early/2021/06/25/2021.06.24.449752.full.pdf) Briefings in Bioinformatics 23.2 (2022): bbab570.

16. Liu, Cheng-Hao, et al. [RetroGNN: Approximating retrosynthesis by graph neural networks for de novo drug design.](https://arxiv.org/pdf/2011.13042) arXiv preprint arXiv:2011.13042 (2020).

17. Dai, Hanjun, et al. [Retrosynthesis prediction with conditional graph logic network.](https://proceedings.neurips.cc/paper/2019/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf) Advances in Neural Information Processing Systems 32 (2019).

18. Tu, Zhengkai, and Connor W. Coley. [Permutation invariant graph-to-sequence model for template-free retrosynthesis and reaction prediction.](https://arxiv.org/pdf/2110.09681) Journal of chemical information and modeling 62.15 (2022): 3503-3513.

19. Somnath, Vignesh Ram, et al. [Learning graph models for retrosynthesis prediction.](https://proceedings.neurips.cc/paper/2021/file/4e2a6330465c8ffcaa696a5a16639176-Paper.pdf) Advances in Neural Information Processing Systems 34 (2021): 9405-9415.

20. Mao, Kelong, et al. [Molecular graph enhanced transformer for retrosynthesis prediction.](https://www.biorxiv.org/content/biorxiv/early/2020/03/09/2020.03.05.979773.full.pdf) Neurocomputing 457 (2021): 193-202.

21. Shi, Chence, et al. [A graph to graphs framework for retrosynthesis prediction.](http://proceedings.mlr.press/v119/shi20d/shi20d.pdf) International conference on machine learning. PMLR, 2020.

22. Han, Peng, et al. [Gnn-retro: Retrosynthetic planning with graph neural networks.](https://ojs.aaai.org/index.php/AAAI/article/download/20318/20077) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 4. 2022.

23. Strokach, Alexey, et al. [Fast and flexible protein design using deep graph neural networks.](https://www.sciencedirect.com/science/article/pii/S2405471220303276) Cell systems 11.4 (2020): 402-411.


24. You, Ronghui, et al. [DeepGraphGO: graph neural network for large-scale, multispecies protein function prediction.](https://academic.oup.com/bioinformatics/article/37/Supplement_1/i262/6319663) Bioinformatics 37.Supplement_1 (2021): i262-i271.


25. Ingraham, John, et al. [Generative models for graph-based protein design.](https://proceedings.neurips.cc/paper/2019/file/f3a4ff4839c56a5f460c88cce3666a2b-Paper.pdf) Advances in neural information processing systems 32 (2019).

26. Fout, Alex, et al. [Protein interface prediction using graph convolutional networks.](https://proceedings.neurips.cc/paper/2017/file/f507783927f2ec2737ba40afbd17efb5-Paper.pdf) Advances in neural information processing systems 30 (2017).

27. Zhang, Zuobai, et al. [Protein representation learning by geometric structure pretraining.](https://arxiv.org/pdf/2203.06125) arXiv preprint arXiv:2203.06125 (2022).

28. Zhang, Zuobai, et al. [Enhancing protein language models with structure-based encoder and pre-training.](https://arxiv.org/pdf/2303.06275) arXiv preprint arXiv:2303.06275 (2023).

29. Chen, Can, et al. [Structure-aware protein self-supervised learning.](https://academic.oup.com/bioinformatics/article/39/4/btad189/7117544) Bioinformatics 39.4 (2023): btad189.

30. Yu, Yue, et al. [DAG-GNN: DAG structure learning with graph neural networks.](http://proceedings.mlr.press/v97/yu19a/yu19a.pdf) International Conference on Machine Learning. PMLR, 2019.

### Partial / Ordinary Differential Equations

1. Poli, Michael, et al. [Graph neural ordinary differential equations.](https://arxiv.org/pdf/1911.07532) arXiv preprint arXiv:1911.07532 (2019).

2. Rusch, T. Konstantin, et al. [Graph-coupled oscillator networks.](https://proceedings.mlr.press/v162/rusch22a/rusch22a.pdf) International Conference on Machine Learning. PMLR, 2022.

3. Xhonneux, Louis-Pascal, Meng Qu, and Jian Tang. [Continuous graph neural networks.](http://proceedings.mlr.press/v119/xhonneux20a/xhonneux20a.pdf) International Conference on Machine Learning. PMLR, 2020.

4.  Zhuang, Juntang, et al. [Ordinary differential equations on graph networks.](https://openreview.net/pdf?id=SJg9z6VFDr) (2020).

5. Chamberlain, Ben, et al. [Grand: Graph neural diffusion.](http://proceedings.mlr.press/v139/chamberlain21a/chamberlain21a.pdf) International Conference on Machine Learning. PMLR, 2021.

6. Thorpe, Matthew, et al. [GRAND++: Graph neural diffusion with a source term.](https://par.nsf.gov/servlets/purl/10320328) International Conference on Learning Representations. 2022.

7. Di Giovanni, Francesco, et al. [Graph neural networks as gradient flows.](https://arxiv.org/pdf/2206.10991) arXiv preprint arXiv:2206.10991 (2022).

8. Jin, Ming, et al. [Multivariate time series forecasting with dynamic graph neural ODEs.](https://ieeexplore.ieee.org/iel7/69/4358933/09950330.pdf?casa_token=XvAML47fTbwAAAAA:DZsuXIJ3q4vSMK4wEruzd6D7nSH-aZ9zUyKzhokuQeiYVYN7Pr9VLWsh2XEbGrg_uDN-gtGX9BJa) IEEE Transactions on Knowledge and Data Engineering (2022).

9. Hadou, Samar, Charilaos I. Kanatsoulis, and Alejandro Ribeiro. [Space-time graph neural networks.](https://arxiv.org/pdf/2110.02880) arXiv preprint arXiv:2110.02880 (2021).

10. Baker, Justin, et al. [Proximal Implicit ODE Solvers for Accelerating Learning Neural ODEs.](https://arxiv.org/pdf/2204.08621) arXiv preprint arXiv:2204.08621 (2022).

11. Elhag, Ahmed AA, et al. [Graph Anisotropic Diffusion.](https://arxiv.org/pdf/2205.00354) arXiv preprint arXiv:2205.00354 (2022).

12. Qin, Yifang, et al. [Learning Graph ODE for Continuous-Time Sequential Recommendation.](https://arxiv.org/pdf/2304.07042) arXiv preprint arXiv:2304.07042 (2023).

13. Nguyen, Khang, et al. [DeepGRAND: Deep Graph Neural Diffusion.](https://openreview.net/pdf?id=wTGORH_cHPX) (2023).

14. Huang, Chuyu. [STR-GODEs: Spatial-Temporal-Ridership Graph ODEs for Metro Ridership Prediction.](https://arxiv.org/pdf/2107.04980) arXiv preprint arXiv:2107.04980 (2021).

15. Xia, Hedi. [Towards Faster and More Accurate Neural ODEs](https://escholarship.org/content/qt1rn6x024/qt1rn6x024.pdf). Diss. University of California, Los Angeles, 2023.

16. Hua, Chuanbo, et al. [Efficient Continuous Spatio-Temporal Simulation with Graph Spline Networks.](https://openreview.net/pdf?id=PBT0Vftuji) ICML 2022 2nd AI for Science Workshop.

17. Di Giovanni, Francesco. [Graph neural networks as dynamical systems.](https://www.sci.unich.it/geodeep2022/slides/GRAFF_presentation%20(17).pdf) 

18. Pal, Soumyasundar. [Monte Carlo algorithms for nonlinear filtering, bayesian graph neural networks, and probabilistic forecasting.](https://escholarship.mcgill.ca/downloads/rv0430529) (2022).


19. Brandstetter, Johannes, Daniel Worrall, and Max Welling. [Message passing neural PDE solvers.](https://arxiv.org/pdf/2202.03376) arXiv preprint arXiv:2202.03376 (2022).

20. Qin, Tiexin, et al. [Learning Dynamic Graph Embeddings with Neural Controlled Differential Equations.](https://arxiv.org/pdf/2302.11354) arXiv preprint arXiv:2302.11354 (2023).

21. Takamoto, Makoto, et al. [PDEBench: An extensive benchmark for scientific machine learning](https://proceedings.neurips.cc/paper_files/paper/2022/file/0a9747136d411fb83f0cf81820d44afb-Paper-Datasets_and_Benchmarks.pdf) Advances in Neural Information Processing Systems 35 (2022): 1596-1611.

22. Sanchez-Gonzalez, Alvaro, et al. [Hamiltonian graph networks with ode integrators.](https://arxiv.org/pdf/1909.12790) arXiv preprint arXiv:1909.12790 (2019). 

23. Ruhe, David, et al. [Geometric clifford algebra networks.](https://arxiv.org/pdf/2302.06594) arXiv preprint arXiv:2302.06594 (2023).

24. Wu, Tailin, Takashi Maruyama, and Jure Leskovec. [Learning to accelerate partial differential equations via latent global evolution.](https://arxiv.org/pdf/2206.07681) arXiv preprint arXiv:2206.07681 (2022).

25. Lütjens, Björn, et al. [Multiscale neural operator: Learning fast and grid-independent pde solvers.](https://arxiv.org/pdf/2207.11417) arXiv preprint arXiv:2207.11417 (2022).

26. Horie, Masanobu, and Naoto Mitsume. [Physics-Embedded Neural Networks: Graph Neural PDE Solvers with Mixed Boundary Conditions.](https://proceedings.neurips.cc/paper_files/paper/2022/file/93476ae409ae3246e22a9d4b931f84ed-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 23218-23229.

27. Equer, Léonard, T. Konstantin Rusch, and Siddhartha Mishra. [Multi-scale message passing neural pde solvers.](https://arxiv.org/pdf/2302.03580) arXiv preprint arXiv:2302.03580 (2023).

28. Lötzsch, Winfried, Simon Ohler, and Johannes S. Otterbach. [Learning the solution operator of boundary value problems using graph neural networks.](https://arxiv.org/pdf/2206.14092) arXiv preprint arXiv:2206.14092 (2022).

29. Wang, Yuelin, et al. [ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition.](https://arxiv.org/pdf/2206.05437) arXiv preprint arXiv:2206.05437 (2022).

30.  Horie, Masanobu, and Naoto Mitsume. [Physics-Embedded Neural Networks: $\boldsymbol {\mathrm {E}(n)} $-Equivariant Graph Neural PDE Solvers.](https://arxiv.org/pdf/2205.11912) arXiv preprint arXiv:2205.11912 (2022).

31. Toshev, Artur P., et al. [Learning Lagrangian Fluid Mechanics with E ($3 $)-Equivariant Graph Neural Networks.](https://arxiv.org/pdf/2305.15603) arXiv preprint arXiv:2305.15603 (2023).

32. Serrano, Louis, et al. [Operator Learning with Neural Fields: Tackling PDEs on General Geometries.](https://arxiv.org/pdf/2306.07266) arXiv preprint arXiv:2306.07266 (2023).

33. Huang, Xinquan, et al. [NeuralStagger: accelerating physics-constrained neural PDE solver with spatial-temporal decomposition.](https://arxiv.org/pdf/2302.10255) arXiv preprint arXiv:2302.10255 (2023).

34. Nastorg, Matthieu, et al. [An Implicit GNN Solver for Poisson-like problems.](https://arxiv.org/pdf/2302.10891) arXiv preprint arXiv:2302.10891 (2023).

35. Boussif, Oussama, et al. [MAgnet: Mesh agnostic neural PDE solver.](https://proceedings.neurips.cc/paper_files/paper/2022/file/cf4c7ee0734cdfe09a099cf6cd7b117a-Paper-Conference.pdf) Advances in Neural Information Processing Systems 35 (2022): 31972-31985.

36. Hua, Chuanbo, et al. [Graph Spline Networks for Efficient Continuous Simulation of Dynamical Systems.](https://openreview.net/pdf?id=loc3CUXeuzH) (2023).

37. Li, Yichen, et al. [NeuralPCG: Learning Preconditioner for Solving Partial Differential Equations with Graph Neural Network.](https://openreview.net/pdf?id=IDSXUFQeZO5) (2023).

38. Li, Qing, et al. [Solving Nonlinear Conservation Laws of Partial Differential Equations Using Graph Neural Networks.](https://septentrio.uit.no/index.php/nldl/article/download/6808/7008) Proceedings of the Northern Lights Deep Learning Workshop. Vol. 4. 2023.

39. Wu, Tailin, et al. [Learning Controllable Adaptive Simulation for Multi-scale Physics.](https://openreview.net/pdf?id=PhktEpJHU3) NeurIPS 2022 AI for Science: Progress and Promises.



### Geology, Transportation and Seismology (Selected)
1. Hillier, Michael, et al. [Three-dimensional structural geological modeling using graph neural networks.](https://link.springer.com/article/10.1007/s11004-021-09945-x) Mathematical Geosciences 53.8 (2021): 1725-1749.

2. Kuang, Ping, et al. [Landslide Displacement Prediction via Attentive Graph Neural Network.](https://www.mdpi.com/2072-4292/14/8/1919/pdf) Remote Sensing 14.8 (2022): 1919.

3. Sun, Alexander Y., et al. [Explore Spatio‐Temporal Learning of Large Sample Hydrology Using Graph Neural Networks.](https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1029/2021WR030394?casa_token=6p2Of4MKudwAAAAA:TzXaJlt500xkSi_pEgAoBKl2ZU-_3S3MAquL8N-HBy_ChoO7544cbV2XEDp7WDo7nkw1cz_Vg-e0Uy6E8A) Water Resources Research 57.12 (2021): e2021WR030394.

4. McBrearty, Ian W., and Gregory C. Beroza. [Earthquake phase association with graph neural networks.](https://pubs.geoscienceworld.org/ssa/bssa/article-pdf/doi/10.1785/0120220182/5764196/bssa-2022182.1.pdf?casa_token=DXulqT6Kr_QAAAAA:uiQ_xIur_9-0kXvK6Ds8zM_bJl2jxu7w81UxJkqXozPVR-fo1di7e17jFwFb8khYSMssXtyS) Bulletin of the Seismological Society of America 113.2 (2023): 524-547.

5. Gong, Renbin, and Yanzi Yang. [Application of Graph Neural Network in Lithology Recognition.](https://ieeexplore.ieee.org/iel7/9885795/9885816/09885832.pdf?casa_token=t7J0StbmeoYAAAAA:Ql0m0LyU0amMEF34lQBlOLFlfJ9XvjQUNwFu2QdVObH9oArWGRb2Rk_cdMgAFbKg0agt3fX5otlQ) 2022 4th International Conference on Natural Language Processing (ICNLP). IEEE, 2022.

6. Zhou, Fan, et al. [Land deformation prediction via slope-aware graph neural networks.](https://ojs.aaai.org/index.php/AAAI/article/download/17764/17571) Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 17. 2021.

7. Li, Rongfan, et al. [Mining Spatio-Temporal Relations via Self-Paced Graph Contrastive Learning.](https://dl.acm.org/doi/pdf/10.1145/3534678.3539422?casa_token=Ijq0k6zsBR4AAAAA:k6rzhXZpbEUy6oA6J16oc5lSeDram8OpuAXyvm9WNHqA4bAJP-gr74Er7VLqlVggpaIXOJT_XX01OAI) Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022.

8. Li, Yun, et al. [Graph Neural Network for spatiotemporal data: methods and applications.](https://arxiv.org/pdf/2306.00012) arXiv preprint arXiv:2306.00012 (2023).

9. Choi, Yongjin, and Krishna Kumar. [Graph Neural Network-based surrogate model for granular flows.](https://arxiv.org/pdf/2305.05218) arXiv preprint arXiv:2305.05218 (2023).

10. McBrearty, Ian W., and Gregory C. Beroza. [Earthquake location and magnitude estimation with graph neural networks.](https://ieeexplore.ieee.org/iel7/9897158/9897159/09897468.pdf?casa_token=lU6Q78jvbYgAAAAA:6QYpeORN5EtHhQVbXODzCkpoT4pkO73KDCAffk0jA2wpvmxit1XfYtM58O72bd8Tua0U8ItsbEHz) 2022 IEEE International Conference on Image Processing (ICIP). IEEE, 2022.

11. McBrearty, Ian W., and Gregory C. Beroza. [Earthquake phase association with graph neural networks.](https://pubs.geoscienceworld.org/ssa/bssa/article-pdf/doi/10.1785/0120220182/5764196/bssa-2022182.1.pdf?casa_token=aVlcJVz6ZU8AAAAA:p8nz1kBfoOH1_5BYty7uFaxz0pmVatR-75DGmHkUxpGkp-LIAblEyARWAQxnk1fcVCvLIrH3) Bulletin of the Seismological Society of America 113.2 (2023): 524-547.

12. Bloemheuvel, Stefan, et al. [Multivariate time series regression with graph neural networks.](https://arxiv.org/pdf/2201.00818) arXiv preprint arXiv:2201.00818 (2022).

13. Bilal, Muhammad Atif, et al. [Early Earthquake Detection Using Batch Normalization Graph Convolutional Neural Network (BNGCNN).](https://www.mdpi.com/2076-3417/12/15/7548/pdf) Applied Sciences 12.15 (2022): 7548.

14. Ruiz, Luana, Fernando Gama, and Alejandro Ribeiro. [Gated graph convolutional recurrent neural networks.](https://ieeexplore.ieee.org/iel7/8893974/8902336/08902995.pdf?casa_token=9a1aPY5i1qwAAAAA:kN2eCqQTZxcFHbVRvzNVsqXmSbu6OGpEDlIuGYyLbDO_xz3dR7ua0rDf8NXjplHNVdDPjHxUEkqr) 2019 27th European Signal Processing Conference (EUSIPCO). IEEE, 2019.

15. Zhao, Wenzhi, et al. [Contextual-Aware Land Cover Classification with U-Shaped Object Graph Neural Network.](https://ieeexplore.ieee.org/iel7/8859/9651998/09781433.pdf?casa_token=QTVwoN3FyocAAAAA:wZdIcM5M-TPmcwe7xO79d2cQJy061bhCsO4BlSLz4uj6aA7burHjeiRNgVW49-Mfc9nN_mQWNc2N) IEEE Geoscience and Remote Sensing Letters 19 (2022): 1-5.

16. Zhou, Fan, et al. [Identifying user geolocation with Hierarchical Graph Neural Networks and explainable fusion.](https://www.sciencedirect.com/science/article/pii/S1566253521002293?casa_token=l1nNwi73DcoAAAAA:aMhRRlmcNaC3tXhmYxJcyouEs-vQXjtkyj7G-pigk7aNHOO9Or6BCCxpgWKnCEMG-IBH9QbV8l1I) Information Fusion 81 (2022): 1-13.

17. Jiang, Weiwei, and Jiayun Luo. [Graph neural network for traffic forecasting: A survey.](https://www.sciencedirect.com/science/article/pii/S0957417422011654?casa_token=e-AJI2pnoZQAAAAA:QucWHxAHPHT-GgHCes8cqdQEkrcC-7l0arDKG--pOxR5MR_BgVybRbG4YpHZxohMPRQiLw2YHykS) Expert Systems with Applications (2022): 117921.

18. Wu, Ning, et al. [Learning effective road network representation with hierarchical graph neural networks.](https://dl.acm.org/doi/pdf/10.1145/3394486.3403043?casa_token=4nktNxSOLikAAAAA:XgroevKJg5vTPAhyMY8FJVEFRvWnCfRO7zFHLLBfGhImhLwdv1MTEGkD7lO-Vl08x0D8jpLpzfgh6tc) Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 2020.

19. Peng, Hao, et al. [Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting.](https://www.sciencedirect.com/science/article/pii/S0020025520300451?casa_token=tB-9F_UvbcMAAAAA:q6fvU-nNi1QJJr0I0ZVm8rkUK-M57le6eB20h2FGvR9TanmH85Yrwjx8vuRKrNmnuERljViVhrQX) Information Sciences 521 (2020): 277-290.

20. Ma, Zhaorui, et al. [GWS-Geo: A graph neural network based model for street-level IPv6 geolocation.](https://www.sciencedirect.com/science/article/pii/S2214212623000959?casa_token=Vei8xcgZVVgAAAAA:JtSHE4wOtp8JTw60ALFZEveiEqwWL3ZLPbBFP-ZkwDZxoYejlTXeNtmM817evQKDAAzWnTzBcQEy) Journal of Information Security and Applications 75 (2023): 103511.

21. Sarlin, Paul-Edouard, et al. [Superglue: Learning feature matching with graph neural networks.](https://openaccess.thecvf.com/content_CVPR_2020/papers/Sarlin_SuperGlue_Learning_Feature_Matching_With_Graph_Neural_Networks_CVPR_2020_paper.pdf) Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.

22. Wang, Xiaoyang, et al. [Traffic flow prediction via spatial temporal graph neural network.](https://dl.acm.org/doi/pdf/10.1145/3366423.3380186?casa_token=lnGEI_wuN5IAAAAA:DEAyd_5HoMXC1YpH9Ba4oOX737sr6dg069OFJkI5TeOvavGsuHmdzYfeR5-ozCiagz-R6WaEXyidh0Y) Proceedings of the web conference 2020. 2020.

23. Zhang, Fang-Hao, and Zhi-Gang Shao. [ST-GRF: Spatiotemporal graph neural networks for rainfall forecasting.](https://www.sciencedirect.com/science/article/pii/S1051200423000842?casa_token=HQ9TdmpIhgAAAAAA:JSypHbk-YTStM6T1uXx4CtZM9jem1dEfWG72x0YD198RYGZKg2T0RPkx9ySOlE_OxN7pNBS2W4Jp) Digital Signal Processing 136 (2023): 103989.

24. Jin, Guangyin, et al. [Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban Computing: A Survey.](https://ieeexplore.ieee.org/iel7/9148594/9158408/09158447.pdf?casa_token=7EtPBQFruZwAAAAA:WfsfDg1S8hz8Fi7Gz3Vo3fYeyn3fLQExm19te2r29jTZCCrGATNfj8wLMl1lB8NwgVk2faXCUWyx) arXiv preprint arXiv:2303.14483 (2023).

25. Chang, Buru, et al. [Learning graph-based geographical latent representation for point-of-interest recommendation.]() Proceedings of the 29th ACM International conference on information & knowledge management. 2020.


26. Tulczyjew, Lukasz, et al. [Graph neural networks extract high-resolution cultivated land maps from Sentinel-2 image series.](https://ieeexplore.ieee.org/iel7/8859/4357975/09803235.pdf?casa_token=A9ZTO7OusIAAAAAA:bsMXJ60tGmvxD24GKIqUUz4s4CnZvRXiiRNkW7yrIL4QRnNsPReWjpJuJJ6YAadNHBX3c6i6BlIk) IEEE Geoscience and Remote Sensing Letters 19 (2022): 1-5.

27. Saha, Sudipan, Shan Zhao, and Xiao Xiang Zhu. [Multitarget domain adaptation for remote sensing classification using graph neural network.](https://ieeexplore.ieee.org/iel7/8859/9651998/09706461.pdf) IEEE Geoscience and Remote Sensing Letters 19 (2022): 1-5.

28. Yan, Jingjing, Shunping Ji, and Yao Wei. [A combination of convolutional and graph neural networks for regularized road surface extraction.](https://ieeexplore.ieee.org/iel7/36/9633014/09714410.pdf) IEEE transactions on geoscience and remote sensing 60 (2022): 1-13.

29. Seastream, Grant, and Huseyin Denli. [Geoscientific reasoning via graph neural networks.](https://onepetro.org/SEGAM/proceedings-abstract/IMAGE22/1-IMAGE22/D011S085R002/512877) SEG/AAPG International Meeting for Applied Geoscience & Energy. OnePetro, 2022.

30. Zhao, Wenzhi, et al. [Contextual-Aware Land Cover Classification with U-Shaped Object Graph Neural Network.](https://ieeexplore.ieee.org/iel7/8859/9651998/09781433.pdf?casa_token=xfXJQaVnpPkAAAAA:cJQmDdmVLbuF6IlqKSfkFL8pKVYbJwFz4BobP_3aSO4o0vx_7B1rsQXzmiLmWa8SfMy0-Tl1cbib) IEEE Geoscience and Remote Sensing Letters 19 (2022): 1-5.

31. Klemmer, Konstantin, Nathan S. Safir, and Daniel B. Neill. [Positional encoder graph neural networks for geographic data.](https://proceedings.mlr.press/v206/klemmer23a/klemmer23a.pdf) International Conference on Artificial Intelligence and Statistics. PMLR, 2023.

### Cosmology, Astrophysics
1. Cranmer, Miles, Peter Melchior, and Brian Nord. [Unsupervised resource allocation with graph neural networks.](http://proceedings.mlr.press/v148/cranmer21a/cranmer21a.pdf) NeurIPS 2020 Workshop on Pre-registration in Machine Learning. PMLR, 2021.

2. Jespersen, Christian Kragh, et al. [$\texttt {Mangrove} $: Learning Galaxy Properties from Merger Trees.](https://arxiv.org/pdf/2210.13473) arXiv preprint arXiv:2210.13473 (2022).

3. Wang, Tianshu, and Peter Melchior. [Graph neural network-based resource allocation strategies for multi-object spectroscopy.](https://iopscience.iop.org/article/10.1088/2632-2153/ac4d12/pdf) Machine Learning: Science and Technology 3.1 (2022): 015023.

4. Farsian, Farida, et al. [New applications of Graph Neural Networks in Cosmology.](https://arxiv.org/pdf/2210.11487) arXiv preprint arXiv:2210.11487 (2022).

5. Villanueva-Domingo, Pablo, et al. [Inferring Halo Masses with Graph Neural Networks.](https://iopscience.iop.org/article/10.3847/1538-4357/ac7aa3/pdf) The Astrophysical Journal 935.1 (2022): 30.

6. Villanueva-Domingo, Pablo, and Francisco Villaescusa-Navarro. [Learning cosmology and clustering with cosmic graphs.](https://iopscience.iop.org/article/10.3847/1538-4357/ac8930/pdf) The Astrophysical Journal 937.2 (2022): 115.

7. Nguyen, Tri, et al. [Uncovering dark matter density profiles in dwarf galaxies with graph neural networks.](https://arxiv.org/pdf/2208.12825) Physical Review D 107.4 (2023): 043015.

8. Koundal, Paras, and IceCube Collaboration. [Composition Analysis of cosmic-rays at IceCube Observatory, using Graph Neural Networks.](https://publikationen.bibliothek.kit.edu/1000143576) Workshop on Machine Learning for Cosmic-Ray Air Showers (2022), Newark, DE, USA, 31.01. 2022–03.02. 2022. 2022.

9. Jagvaral, Yesukhei, et al. [Galaxies on graph neural networks: towards robust synthetic galaxy catalogs with deep generative models.](https://arxiv.org/pdf/2212.05596) arXiv preprint arXiv:2212.05596 (2022).

10. Choma, Nicholas, et al. [Graph neural networks for icecube signal classification.](https://arxiv.org/pdf/1809.06166) 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2018.

11. Reck, S., et al. [Graph neural networks for reconstruction and classification in KM3NeT.](https://arxiv.org/pdf/2107.13375) Journal of Instrumentation 16.10 (2021): C10011.

12. Koundal, Paras, Matthias Plum, and Julian Saffer. [Study of mass composition of cosmic rays with IceTop and IceCube.](https://arxiv.org/pdf/2107.09626) arXiv preprint arXiv:2107.09626 (2021).

13. ...


## TODO List:
1. Energy based Graph Neural Networks (First Part)
2. Finding more references on spectral graph theories with graph neural networks (Traditional Analysis + Learning Based Methods) in first part

This repo is going to be frequently updated. Some new theoretical papers will be added. Old papers or unimportant papers will be removed after careful considerations.
